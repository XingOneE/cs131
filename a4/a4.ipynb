{"cells":[{"cell_type":"code","execution_count":1,"id":"4f39ed03","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/04/19 01:51:48 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]}],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"CS131_A4_DecisionTree\").getOrCreate() \n"]},{"cell_type":"code","execution_count":2,"id":"fb5b76fd","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["csv_path = \"gs://dataproc-staging-us-central1-1084640347746-mwcssbrt/data/2019-01-h1.csv\"  # update to your actual GCS path\n","df = spark.read.csv(csv_path, header=True, inferSchema=True)\n"]},{"cell_type":"code","execution_count":9,"id":"ef26322e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Select required columns and filter out invalid rows (e.g., passenger_count == 0.0)\n","selected = df.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\") \\\n","             .dropna() \\\n","             .filter(\"passenger_count > 0\")\n","\n","selected.show(10)\n"]},{"cell_type":"code","execution_count":10,"id":"4d08aaee","metadata":{},"outputs":[],"source":["trainDF, testDF = selected.randomSplit([0.8, 0.2], seed=42)\n"]},{"cell_type":"code","execution_count":11,"id":"1a5ef6e7","metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import DecisionTreeRegressor\n","from pyspark.ml import Pipeline\n","\n","assembler = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\", \"dolocationid\"], outputCol=\"features\")\n","dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"total_amount\", maxBins=100)\n","pipeline = Pipeline(stages=[assembler, dt])\n"]},{"cell_type":"code","execution_count":13,"id":"19a99963","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["model = pipeline.fit(trainDF)\n"]},{"cell_type":"code","execution_count":14,"id":"3c0ef4ad","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 48:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+------------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|        prediction|\n","+---------------+------------+------------+------------+------------------+\n","|            1.0|         1.0|         1.0|        15.3|22.793349915525248|\n","|            1.0|         1.0|         1.0|       24.36|22.793349915525248|\n","|            1.0|         1.0|         1.0|        40.3|22.793349915525248|\n","|            1.0|         1.0|         1.0|        65.3|22.793349915525248|\n","|            1.0|         1.0|         1.0|        93.8|22.793349915525248|\n","|            1.0|         1.0|         1.0|       100.3|22.793349915525248|\n","|            1.0|         1.0|         1.0|       105.3|22.793349915525248|\n","|            1.0|         1.0|         1.0|      115.56|22.793349915525248|\n","|            1.0|         3.0|         3.0|        48.8|22.793349915525248|\n","|            1.0|         3.0|         3.0|        50.8|22.793349915525248|\n","+---------------+------------+------------+------------+------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["predictions = model.transform(testDF)\n","predictions.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\", \"prediction\").show(10)\n"]},{"cell_type":"code","execution_count":15,"id":"ba0e1071","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 49:===========================================>              (3 + 1) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["Root Mean Squared Error (RMSE): 10.17763249423234\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","\n","evaluator = RegressionEvaluator(labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = evaluator.evaluate(predictions)\n","print(\"Root Mean Squared Error (RMSE):\", rmse)\n"]},{"cell_type":"code","execution_count":null,"id":"c49c7f57","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}